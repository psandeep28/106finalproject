#+title: Model

* Load and prep Data
#+begin_src python :results table :session
import math
import tensorflow as tf
import pandas as pd
# from tensorflow.keras import layers

sampled = ['Work Pressure', 'Sleep Duration', 'Depression', 'Financial Stress', 'Work/Study Hours']
data = pd.read_csv('data/student_depression_dataset.csv')[sampled]
data['Sleep Duration'] = data['Sleep Duration'].map({
    "'5-6 hours'": 2,
    "'Less than 5 hours'": 1,
    "'7-8 hours'": 3,
    "'More than 8 hours'": 4,
    'Others': 0
})
data = data[data['Financial Stress'] != '?']
data['Financial Stress'] = data["Financial Stress"].apply(float)
train_X = data[data['Sleep Duration'] > 0]
test_X = train_X.loc[train_X.sample(frac=0.2).index]
test_y = test_X.pop('Depression').to_numpy()
train_y = train_X.pop('Depression').to_numpy()
train_X.head()
#+end_src

#+RESULTS:
|   | Work Pressure | Sleep Duration | Financial Stress | Work/Study Hours |
|---+---------------+----------------+------------------+------------------|
| 0 |           0.0 |            2.0 |              1.0 |              3.0 |
| 1 |           0.0 |            2.0 |              2.0 |              3.0 |
| 2 |           0.0 |            1.0 |              1.0 |              9.0 |
| 3 |           0.0 |            3.0 |              5.0 |              4.0 |
| 4 |           0.0 |            2.0 |              1.0 |              1.0 |

* Train Model
#+begin_src python :session :results verbatim
layers = tf.keras.layers
train_X = train_X.to_numpy()
test_X = test_X.to_numpy()

normalize = layers.Normalization()
normalize.adapt(train_X)
model = tf.keras.Sequential([
    normalize,
    layers.Dense(64, activation='relu'),
    layers.Dense(64, activation='relu'),
    layers.Dense(1, activation='sigmoid')
])
#+end_src

#+RESULTS:
: None

#+begin_src python :results none :session
model.compile(loss = tf.keras.losses.BinaryCrossentropy(), optimizer = tf.keras.optimizers.Adam())
model.fit(train_X, train_y, epochs=10)
#+end_src

#+begin_src python :session :results value
probs = model.predict(test_X)
predictions = (probs >= 0.5).astype(int)
model.save('predictor.h5')
(predictions.flatten() == test_y).sum() / test_y.shape[0]
#+end_src

#+RESULTS:
: 0.6924318507890961
